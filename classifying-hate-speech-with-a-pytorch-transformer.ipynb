{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link to this kaggle kernel: https://www.kaggle.com/nadergo/classifying-hate-speech-with-a-pytorch-transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this kernel is to train a simple transformer from only pytorch to classify hate speech in comments\n",
    "to understand how the transformer works, I would recommend this video it walks through the Attention paper and explains it well\n",
    "\n",
    "https://www.youtube.com/watch?v=U0s0f995w14&t=2522s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using  torchtext it's really good for preparing the data, it has a good documentation also \n",
    "those are links about an example using torchtext and a tutorial\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/01/first-text-classification-in-pytorch/\n",
    "\n",
    "http://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as this will be a classification task, we will just need the encoder part of the transformer, so I used the transformer encoder layer from pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cj9NXWy3zd4T",
    "outputId": "0d72ee04-eea7-42f6-e1f0-d7fccc461a9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu up\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "SEED = 32\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import  f1_score\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "from torchtext import data\n",
    "from torch.nn  import functional as F\n",
    "import torch.optim as  optim \n",
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "  print(\"gpu up\")\n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "k5O16FLBzhuC",
    "outputId": "6f53909e-a92b-46c6-ed25-95a67abfc8ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "those are the libraries I use for processing text\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "import re\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from nltk.stem  import PorterStemmer\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stops = stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "def removepunc(my_str): # function to remove punctuation\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    no_punct = \"\"\n",
    "    for char in my_str:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "    return no_punct\n",
    "\n",
    "def hasNumbers(inputString):\n",
    "    return bool(re.search(r'\\d', inputString))\n",
    "snowstem = SnowballStemmer(\"english\")\n",
    "portstem = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "elXvdWQyzkDw"
   },
   "outputs": [],
   "source": [
    "traindata = pd.read_csv(\"/kaggle/input/hate-speech-detection/toxic_train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/hate-speech-detection/toxic_test.csv\")\n",
    "traindata.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
    "test.drop(\"Unnamed: 0\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lTDXODNhzwwz"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this function is the tokenizer we are using, it does basic processing also  like ,\n",
    "Lowercase the text\n",
    "removing punctuation, stop words and numbers,\n",
    "it also removes extra spaces and unwanted characters (I use regex for that)\n",
    "\n",
    "\n",
    "before using the tokenizer I was testing it on the train dataframe manually  \n",
    "\"\"\"\n",
    "\n",
    "def myTokenizer(x):\n",
    " return  [snowstem.stem(word.text)for word in \n",
    "          tokenizer(removepunc(re.sub(r\"\\s+\\s+\",\" \",re.sub(r\"[^A-Za-z0-9()!?\\'\\`\\\"\\r+\\n+]\",\" \",x.lower()))).strip()) \n",
    "          if (word.text not in stops and not hasNumbers(word.text)) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "udmV7yOmPNt6"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "here I'm using the torchtext fields and dataset classes they can ease the work to get\n",
    "the dataset ready for the pytorch model\n",
    "\n",
    "the class DataFrameDataset is the easiest way I found to turn a dataframe into a torchtext dataset\n",
    "\n",
    "this cell will take sometime to finish\n",
    "\"\"\"\n",
    "\n",
    "TEXT = data.Field(tokenize=myTokenizer,batch_first=True,fix_length=140)\n",
    "LABEL = data.LabelField(dtype=torch.float ,batch_first=True)\n",
    "\n",
    "\n",
    "class DataFrameDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, df, text_field, label_field, is_test=False, **kwargs):\n",
    "        fields = [('comment_text', text_field), ('toxic', label_field)]\n",
    "        examples = []\n",
    "        for i, row in df.iterrows():\n",
    "            label = row.toxic \n",
    "            text = row.comment_text\n",
    "            examples.append(data.Example.fromlist([text, label], fields))\n",
    "\n",
    "        super().__init__(examples, fields, **kwargs)\n",
    "  \n",
    "\n",
    "torchdataset = DataFrameDataset(traindata, TEXT,LABEL)\n",
    "torchtest = DataFrameDataset(test, TEXT,LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-f1hgGywizQT"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = torchdataset.split(split_ratio=0.8, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "O6PUzivRJvL_"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this cell build the vocab which means it get all the used words and if also ignores any word \n",
    "that only appeared less than 3 times\n",
    "\"\"\"\n",
    "TEXT.build_vocab(train_data,min_freq=3)  \n",
    "LABEL.build_vocab(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QojEJaoBVTJj",
    "outputId": "528174ce-a162-47bf-edb4-ab3358bf296a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TEXT vocabulary: 38591\n",
      "Size of LABEL vocabulary: 2\n",
      "[('articl', 59408), ('page', 45801), ('wikipedia', 38257), ('edit', 33298), ('talk', 32102), ('use', 28301), ('one', 24706), ('like', 24462), ('pleas', 23766), ('would', 23436)]\n"
     ]
    }
   ],
   "source": [
    "#No. of unique tokens in text\n",
    "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
    "\n",
    "#No. of unique tokens in label\n",
    "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n",
    "\n",
    "#Commonly used words\n",
    "print(TEXT.vocab.freqs.most_common(10))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JVrwFrmTqHzc"
   },
   "outputs": [],
   "source": [
    "#set batch size\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\"\"\"\n",
    "we are using batches for validation and test set because of memory usage we can't pass the whole set at once \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "train_iterator,valid_iterator,test_iterator= data.BucketIterator.splits(\n",
    "    (train_data,valid_data,torchtest), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    sort =False,\n",
    "shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "QA57LLmjMCX3",
    "outputId": "964eb82a-0855-4675-a5c7-7ae4f6859d1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextTransformer(\n",
       "  (wordEmbeddings): Embedding(38591, 140)\n",
       "  (positionEmbeddings): Embedding(140, 20)\n",
       "  (transformerLayer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=160, out_features=2048, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear2): Linear(in_features=2048, out_features=160, bias=True)\n",
       "    (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (linear1): Linear(in_features=160, out_features=64, bias=True)\n",
       "  (linear2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (linear3): Linear(in_features=140, out_features=16, bias=True)\n",
       "  (linear4): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "one major point here is that I encoded the embeddings in a different way \n",
    "I made an embedding layer for the position then I concatenated position embeddings with the word embeddings \n",
    "just thought it could be a usefull way to encode the positions \n",
    "\n",
    "had to reshape the output of the transformer layer to get the prediction\n",
    "\"\"\"\n",
    "class TextTransformer(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(TextTransformer,self).__init__()\n",
    "    self.wordEmbeddings = nn.Embedding(len(TEXT.vocab),140)\n",
    "    self.positionEmbeddings = nn.Embedding(140,20)\n",
    "    self.transformerLayer = nn.TransformerEncoderLayer(160,8) \n",
    "    self.linear1 = nn.Linear(160,  64)\n",
    "    self.linear2 = nn.Linear(64,  1)\n",
    "    self.linear3 = nn.Linear(140,  16)\n",
    "    self.linear4 = nn.Linear(16,  1)\n",
    "  def forward(self,x):\n",
    "    positions = (torch.arange(0,140).reshape(1,140) + torch.zeros(x.shape[0],140)).to(device) \n",
    "    # broadcasting the tensor of positions \n",
    "    sentence = torch.cat((self.wordEmbeddings(x.long()),self.positionEmbeddings(positions.long())),axis=2)\n",
    "    attended = self.transformerLayer(sentence)\n",
    "    linear1 = F.relu(self.linear1(attended))\n",
    "    linear2 = F.relu(self.linear2(linear1))\n",
    "    linear2 = linear2.view(-1,140) # reshaping the layer as the transformer outputs a 2d tensor (or 3d considering the batch size)\n",
    "    linear3 = F.relu(self.linear3(linear2))\n",
    "    out = torch.sigmoid(self.linear4(linear3))\n",
    "    return out\n",
    "\n",
    "myTransformer = TextTransformer()\n",
    "myTransformer.to(device)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OQOBpRBUAyAk"
   },
   "outputs": [],
   "source": [
    "def calculateMetrics(ypred,ytrue):\n",
    "  acc  = accuracy_score(ytrue,ypred)\n",
    "  f1  = f1_score(ytrue,ypred)\n",
    "  f1_average  = f1_score(ytrue,ypred,average=\"macro\")\n",
    "  return \" f1 score: \"+str(round(f1,3))+\" f1 average: \"+str(round(f1_average,3))+\" accuracy: \"+str(round(acc,3))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zbLZTzgxJRIA",
    "outputId": "21fbc41e-a284-4267-d3ca-0c10387db2a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train BCE loss:  0.3100277781486511  f1 score: 0.002 f1 average: 0.476 accuracy: 0.903\n",
      "validation BCE loss:  0.2964196801185608  f1 score: 0.001 f1 average: 0.475 accuracy: 0.905\n",
      "train BCE loss:  0.27820736169815063  f1 score: 0.007 f1 average: 0.478 accuracy: 0.904\n",
      "validation BCE loss:  0.25836822390556335  f1 score: 0.018 f1 average: 0.484 accuracy: 0.905\n",
      "train BCE loss:  0.2364715188741684  f1 score: 0.164 f1 average: 0.559 accuracy: 0.911\n",
      "validation BCE loss:  0.22028805315494537  f1 score: 0.285 f1 average: 0.621 accuracy: 0.918\n",
      "train BCE loss:  0.20641660690307617  f1 score: 0.404 f1 average: 0.682 accuracy: 0.924\n",
      "validation BCE loss:  0.19979296624660492  f1 score: 0.45 f1 average: 0.706 accuracy: 0.928\n",
      "train BCE loss:  0.18822012841701508  f1 score: 0.501 f1 average: 0.732 accuracy: 0.932\n",
      "validation BCE loss:  0.18596026301383972  f1 score: 0.52 f1 average: 0.742 accuracy: 0.934\n",
      "train BCE loss:  0.1749427169561386  f1 score: 0.558 f1 average: 0.762 accuracy: 0.937\n",
      "validation BCE loss:  0.1745479255914688  f1 score: 0.562 f1 average: 0.764 accuracy: 0.938\n",
      "train BCE loss:  0.16431690752506256  f1 score: 0.603 f1 average: 0.786 accuracy: 0.942\n",
      "validation BCE loss:  0.16594341397285461  f1 score: 0.598 f1 average: 0.784 accuracy: 0.942\n",
      "train BCE loss:  0.15586669743061066  f1 score: 0.64 f1 average: 0.805 accuracy: 0.946\n",
      "validation BCE loss:  0.1595478057861328  f1 score: 0.626 f1 average: 0.798 accuracy: 0.945\n",
      "train BCE loss:  0.14949537813663483  f1 score: 0.667 f1 average: 0.82 accuracy: 0.949\n",
      "validation BCE loss:  0.15477420389652252  f1 score: 0.652 f1 average: 0.812 accuracy: 0.947\n",
      "train BCE loss:  0.144425168633461  f1 score: 0.685 f1 average: 0.829 accuracy: 0.951\n",
      "validation BCE loss:  0.15112121403217316  f1 score: 0.664 f1 average: 0.818 accuracy: 0.948\n",
      "train BCE loss:  0.14052310585975647  f1 score: 0.698 f1 average: 0.836 accuracy: 0.952\n",
      "validation BCE loss:  0.14837238192558289  f1 score: 0.669 f1 average: 0.821 accuracy: 0.949\n",
      "train BCE loss:  0.13758186995983124  f1 score: 0.708 f1 average: 0.842 accuracy: 0.953\n",
      "validation BCE loss:  0.14606145024299622  f1 score: 0.681 f1 average: 0.827 accuracy: 0.95\n",
      "train BCE loss:  0.13452255725860596  f1 score: 0.717 f1 average: 0.846 accuracy: 0.954\n",
      "validation BCE loss:  0.14416690170764923  f1 score: 0.686 f1 average: 0.83 accuracy: 0.951\n",
      "train BCE loss:  0.13247431814670563  f1 score: 0.724 f1 average: 0.85 accuracy: 0.955\n",
      "validation BCE loss:  0.14316590130329132  f1 score: 0.692 f1 average: 0.833 accuracy: 0.951\n",
      "train BCE loss:  0.13019157946109772  f1 score: 0.728 f1 average: 0.852 accuracy: 0.956\n",
      "validation BCE loss:  0.1416696310043335  f1 score: 0.697 f1 average: 0.835 accuracy: 0.952\n",
      "train BCE loss:  0.12847259640693665  f1 score: 0.732 f1 average: 0.854 accuracy: 0.956\n",
      "validation BCE loss:  0.14120671153068542  f1 score: 0.693 f1 average: 0.833 accuracy: 0.951\n",
      "train BCE loss:  0.1265459656715393  f1 score: 0.737 f1 average: 0.857 accuracy: 0.957\n",
      "validation BCE loss:  0.13982662558555603  f1 score: 0.699 f1 average: 0.836 accuracy: 0.951\n",
      "train BCE loss:  0.1254383623600006  f1 score: 0.741 f1 average: 0.859 accuracy: 0.957\n",
      "validation BCE loss:  0.13933224976062775  f1 score: 0.704 f1 average: 0.839 accuracy: 0.953\n",
      "train BCE loss:  0.12397575378417969  f1 score: 0.744 f1 average: 0.86 accuracy: 0.958\n",
      "validation BCE loss:  0.13771289587020874  f1 score: 0.708 f1 average: 0.841 accuracy: 0.953\n",
      "train BCE loss:  0.12282437086105347  f1 score: 0.747 f1 average: 0.862 accuracy: 0.958\n",
      "validation BCE loss:  0.13712391257286072  f1 score: 0.706 f1 average: 0.84 accuracy: 0.952\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "using adagrad because it assign bigger updates to less frequently updated weights \n",
    "(like words that are not used many times)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "optimizer = optim.Adagrad(myTransformer.parameters(),lr = 0.001)\n",
    "\n",
    "for i in range(20):\n",
    "  trainpreds = torch.tensor([])\n",
    "  traintrues = torch.tensor([])\n",
    "  for  batch in train_iterator:\n",
    "    X = batch.comment_text\n",
    "    y = batch.toxic\n",
    "    myTransformer.zero_grad()\n",
    "    pred = myTransformer(X).squeeze()\n",
    "    trainpreds = torch.cat((trainpreds,pred.cpu().detach()))\n",
    "    traintrues = torch.cat((traintrues,y.cpu().detach()))\n",
    "    err = F.binary_cross_entropy(pred,y)\n",
    "    err.backward()\n",
    "    optimizer.step()\n",
    "  err = F.binary_cross_entropy(trainpreds,traintrues)\n",
    "  print(\"train BCE loss: \",err.item(),calculateMetrics(torch.round(trainpreds).numpy(),traintrues.numpy()))\n",
    " \n",
    "\n",
    "  valpreds = torch.tensor([])\n",
    "  valtrues = torch.tensor([])\n",
    "  for batch in valid_iterator:\n",
    "    X = batch.comment_text\n",
    "    y = batch.toxic\n",
    "    valtrues = torch.cat((valtrues,y.cpu().detach()))\n",
    "    pred = myTransformer(X).squeeze().cpu().detach()\n",
    "    # print(valtrues.shape)\n",
    "    valpreds = torch.cat((valpreds,pred))\n",
    "  err = F.binary_cross_entropy(valpreds,valtrues)\n",
    "  print(\"validation BCE loss: \",err.item(),calculateMetrics(torch.round(valpreds).numpy(),valtrues.numpy()))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so the final scores on validation are  \n",
    "\n",
    "validation BCE loss:  0.137 f1 score: 0.706 f1 average: 0.84 accuracy: 0.952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vordglMh4GGC",
    "outputId": "b65b56fa-c86c-449d-8c97-83e479f537fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test BCE loss:  0.18907569348812103  f1 score: 0.646 f1 average: 0.804 accuracy: 0.932\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "now getting the results on the test set\n",
    "\"\"\"\n",
    "\n",
    "testpreds = torch.tensor([])\n",
    "testtrues = torch.tensor([])\n",
    "for batch in test_iterator:\n",
    "    X = batch.comment_text\n",
    "    y = batch.toxic\n",
    "    testtrues = torch.cat((testtrues,y.cpu().detach()))\n",
    "    pred = myTransformer(X).squeeze().cpu().detach()\n",
    "    # print(valtrues.shape)\n",
    "    testpreds = torch.cat((testpreds,pred))\n",
    "err = F.binary_cross_entropy(testpreds,testtrues)\n",
    "print(\"test BCE loss: \",err.item(),calculateMetrics(torch.round(testpreds).numpy(),testtrues.numpy()))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>you fucking braindead oroszka 50% of the syria...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>\" \\r\\n :::::\"\"This I hate Eagles 247 for. sinc...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>cause she's just a devil with evil on her mind...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>\" \\r\\n ::Can you cite any policies?  If not, w...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Agreed, it is stupid to say that any Malfoy is...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          comment_text  toxic  predicted\n",
       "342  you fucking braindead oroszka 50% of the syria...      1        1.0\n",
       "357  \" \\r\\n :::::\"\"This I hate Eagles 247 for. sinc...      1        1.0\n",
       "370  cause she's just a devil with evil on her mind...      1        1.0\n",
       "375  \" \\r\\n ::Can you cite any policies?  If not, w...      1        1.0\n",
       "392  Agreed, it is stupid to say that any Malfoy is...      0        1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"predicted\"] = torch.round(testpreds).numpy()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "this shows that the model understands the language well \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "test[test.predicted==1].iloc[32:37]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
